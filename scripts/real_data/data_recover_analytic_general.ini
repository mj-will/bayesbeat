[General]
; Output directory
output = outdir_compute_coeffs_x_offset_a_2_constraint/
; Label
label = compute_coeffs
; Path to data
datafile = ../../data/2024_02_23/PyTotalAnalysis.mat
injection = False
indices = [0, 1, 10, 11, 21, 22, 30, 31, 21, 40, 41]
seed = 1234
plot = True

[Data]
; Don't think we need these
rescale-amplitude = False
maximum-amplitude = None

[Model]
name = GenericAnalyticGaussianBeam
; Name of the equation to use
equation_name = General_Equation_7_Terms
; Number of terms in the ERF expansion
n_terms = 7
; Think this isn't actually used
photodiode-size = 1e-2
; These values are consistent with those used to generate the files Bryan provided
photodiode-gap = 1e-3
; Beam radius
beam_radius = 3e-3
; Include the gap
include_gap = True
; Enforce a_1 > a_2, remove this if sampling 'a_ratio'
amplitude_constraint = True
; Assume the d = s(1 + n) model
rin_noise = True
; Priors bounds
prior_bounds = {"a_1": [1e-8, 1e-4], "a_2": [1e-10, 1e-4], "a_scale": [1e-6, 1e2], "dphi": [0, 3.141592654], "domega": [-1, 1], "tau_1": [0, 3000], "tau_2": [0, 3000], "sigma_noise": [0.0, 1.0], "x_offset": [-1e-5, 1e-5]}

[Analysis]
; n-pool will be set automatically if submitting via HTCondor/Slurm
resume = False

[Sampler]
nlive = 1000
; Uncomment this to force torch to use float64
; torch_dtype = "float64"
reset_flow = 4
volume_fraction = 0.95
flow_config = {"patience": 10, "model_config": {"n_neurons": 32, "n_blocks": 6}}
use_default_reparameterisations = True
fallback_reparameterisation = "z-score"


[Slurm]
; Change this to HTCondor if need be
partition = "sciama2.q"
cpus_per_task = 16
time = "4:00:00"
mem = "8GB"
nodes = 1
